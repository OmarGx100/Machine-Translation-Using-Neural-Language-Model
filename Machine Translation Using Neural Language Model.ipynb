{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name : Machine Translation Using Neural Language Model\n",
    "---\n",
    "## Author : Omar Mahmoud Abdel Rahman\n",
    "---\n",
    "## Date : 17/8/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate, Dot, Activation, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow import argmax\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data text file\n",
    "data_dir = './Data/fra.txt'\n",
    "data_path = Path(data_dir)\n",
    "with open(data_path, 'r', encoding= \"utf-8\") as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "# Training samples we are going to train our model on \n",
    "num_samples = 10000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : (10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input      target\n",
       "0   Go.        Va !\n",
       "1   Go.     Marche.\n",
       "2   Go.  En route !\n",
       "3   Go.     Bouge !\n",
       "4   Hi.     Salut !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing inputs and target lists\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "# putting our data into inputs and outputs format\n",
    "for line in lines[:num_samples]:\n",
    "    input, target, _ = line.split('\\t')\n",
    "    inputs.append(input)\n",
    "    targets.append(target)\n",
    "\n",
    "# putting our data into a dataframe\n",
    "lines = pd.DataFrame({'input': inputs,\n",
    "                      'target': targets})\n",
    "\n",
    "lines = lines[:num_samples]\n",
    "print(f\"data shape : {lines.shape}\")\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lines(lines:pd.DataFrame):\n",
    "    lines.input = lines.input.apply(lambda x : x.lower())\n",
    "    lines.target = lines.target.apply(lambda x : x.lower())\n",
    "\n",
    "    # Removing single qoutes also replacing ',' with a COMMA token for the model to capture sepration between words easly \n",
    "    lines.input = lines.input.apply(lambda x : re.sub(\"'\", \"\", x)).apply(lambda x : re.sub(',', \" COMMA\", x))\n",
    "    lines.target = lines.target.apply(lambda x : re.sub(\"'\", \"\", x)).apply(lambda x : re.sub(',', \" COMMA\", x))\n",
    "    \n",
    "    # Clean up punctuations and digits. Such special chars are common to both domains, and can just be copied with no error.\n",
    "    exclude = set(string.punctuation)\n",
    "    lines.input=lines.input.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "    lines.target=lines.target.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    lines.input=lines.input.apply(lambda x: x.translate(remove_digits))\n",
    "    lines.target=lines.target.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "\n",
    "start_tok = \"START_\"\n",
    "end_tok = \"_END\"\n",
    "\n",
    "def prepare_data(lines : pd.DataFrame):\n",
    "    clean_lines(lines)\n",
    "    lines.target = lines.target.apply(lambda x : (start_tok + ' ' + x + ' ' + end_tok))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ va  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ marche _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ en route  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ bouge  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi</td>\n",
       "      <td>START_ salut  _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input                 target\n",
       "0    go        START_ va  _END\n",
       "1    go     START_ marche _END\n",
       "2    go  START_ en route  _END\n",
       "3    go     START_ bouge  _END\n",
       "4    hi     START_ salut  _END"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data(lines)\n",
    "\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Level Model (Word2Word)\n",
    "\n",
    "here we are seeking to create our vocabulary for both inputs \"English words\" and targets \"Franch words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_split_word2word(data):\n",
    "    return data.split()\n",
    "\n",
    "tok_split_fn = tok_split_word2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_tok = \"PAD\"\n",
    "sep_tok = ' '\n",
    "special_tokens = [pad_tok, sep_tok, start_tok, end_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(lines, input_tok_split_fn, target_tok_split_fn):\n",
    "    english_tok = set()\n",
    "    for line in lines.input:\n",
    "        for tok in input_tok_split_fn(line):\n",
    "            if tok not in english_tok :\n",
    "                english_tok.add(tok)\n",
    "    \n",
    "    french_tok = set()\n",
    "    for line in lines.target:\n",
    "        for tok in target_tok_split_fn(line):\n",
    "            if tok not in special_tokens:\n",
    "                if tok not in french_tok :\n",
    "                    french_tok.add(tok)\n",
    "    \n",
    "    english_tok = list(sorted(english_tok))\n",
    "    french_tok = list(sorted(french_tok))\n",
    "\n",
    "    num_encoder_tokens = len(english_tok)\n",
    "    num_decoder_tokens = len(french_tok)\n",
    "\n",
    "    \n",
    "    maximum_encoder_len_seq = np.max([len(input_tok_split_fn(l)) for l in lines.input])\n",
    "    maximum_decoder_len_seq = np.max([len(target_tok_split_fn(l)) for l in lines.target])\n",
    "\n",
    "\n",
    "    return english_tok, french_tok, num_decoder_tokens, num_encoder_tokens, maximum_decoder_len_seq, maximum_encoder_len_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tok, french_tok, num_decoder_tokens, num_encoder_tokens, maximum_decoder_len_seq, maximum_encoder_len_seq = data_stats(lines,\n",
    "                                                                                                                               tok_split_fn,\n",
    "                                                                                                                               tok_split_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 2022\n",
      "Number of unique output tokens: 4410\n",
      "Max sequence length for inputs: 5\n",
      "Max sequence length for outputs: 12\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(lines))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', maximum_encoder_len_seq)\n",
    "print('Max sequence length for outputs:', maximum_decoder_len_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making vocab index dict reserving a 4 more tokens for `<SOS>`, `<EOS>`, `<PAD>`, `<SEP>` tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens += len(special_tokens)\n",
    "num_decoder_tokens += len(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vocab(input_tokens, target_tokens):\n",
    "  \n",
    "  input_token_index = {}\n",
    "  target_token_index = {}\n",
    "  for i,tok in enumerate(special_tokens):\n",
    "    input_token_index[tok] = i\n",
    "    target_token_index[tok] = i \n",
    "\n",
    "  offset = len(special_tokens)\n",
    "  for i, tok in enumerate(input_tokens):\n",
    "    input_token_index[tok] = i+offset\n",
    "\n",
    "  for i, tok in enumerate(target_tokens):\n",
    "    target_token_index[tok] = i+offset\n",
    "   \n",
    "  # Reverse-lookup token index to decode sequences back to something readable.\n",
    "  reverse_input_tok_index = dict(\n",
    "      (i, tok) for tok, i in input_token_index.items())\n",
    "  reverse_target_tok_index = dict(\n",
    "      (i, tok) for tok, i in target_token_index.items())\n",
    "  return input_token_index, target_token_index, reverse_input_tok_index, reverse_target_tok_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_to_idx, french_to_idx, idx_to_english, idx_to_french = vocab(english_tok, french_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to vectorize our data i.e. Converting our text data into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = 16\n",
    "max_decoder_seq_length = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as tf.keras uses a static graph so we need 3 kinds of input data \"encoder inputs which is our data inputs\", \"decoder targets which is our data targets\" and finally \"decoder inputs we need this inputs for \"teacher forcing\" which is the same as our data targets but shifted by one\"\n",
    "def init_model_inputs(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens):\n",
    "    encoder_input_data = np.zeros((len(lines.input), max_encoder_seq_length), dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(lines.target), max_decoder_seq_length), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(lines.target), max_decoder_seq_length, num_decoder_tokens), dtype= 'float32')\n",
    "    print(f\"Encoder_Input_Data_Shape : {encoder_input_data.shape}\")\n",
    "    print(f\"Decoder_Input_Data_Shape : {decoder_input_data.shape}\")\n",
    "    print(f\"Decoder_Target_Data_Shape : {decoder_target_data.shape}\")\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens, input_tok_split_fn, target_tok_split_fn, english_to_idx, french_to_idx):\n",
    "    \n",
    "    encoder_input_data, decoder_input_data, decoder_target_data = init_model_inputs(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens)\n",
    "    \n",
    "    \n",
    "    for i , (input_text, target_text) in enumerate(zip(lines.input, lines.target)):\n",
    "        \n",
    "        \n",
    "        for t, tok in enumerate(input_tok_split_fn(input_text)):\n",
    "            encoder_input_data[i, t] = english_to_idx[tok]\n",
    "            \n",
    "        \n",
    "        encoder_input_data[i, t + 1: ] = english_to_idx[pad_tok]\n",
    "        \n",
    "        \n",
    "        for t, tok in enumerate(target_tok_split_fn(target_text)):\n",
    "            decoder_input_data[i, t] = french_to_idx[tok]\n",
    "        \n",
    "            if t > 0:\n",
    "                # decoder target data will not include start token\n",
    "                decoder_target_data[i, t - 1][french_to_idx[tok]] = 1\n",
    "        \n",
    "        \n",
    "        decoder_input_data[i, t + 1:] = french_to_idx[pad_tok]\n",
    "        \n",
    "        decoder_target_data[i, t:, french_to_idx[pad_tok]] = 1\n",
    "\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder_Input_Data_Shape : (10000, 16)\n",
      "Decoder_Input_Data_Shape : (10000, 16)\n",
      "Decoder_Target_Data_Shape : (10000, 16, 4414)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = vectorize(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens, tok_split_fn, tok_split_fn, english_to_idx, french_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we can notice that for the very begining data we only have small number of words in each seq so we see alot of padding\n",
    "- we are going to build to distinct models \n",
    "    - one with out masking zero \"i.e we will make the model learn the padding\" which will lead to fake accuracy\n",
    "    - and the other model is `with mask_zero = true` in the embedding layer and we will notice that the accuracy went down because it was fake one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(num_decoder_tokens, num_encoder_tokens, emb_sz, lstm_sz):\n",
    "  encoder_inputs = Input(shape=(None,))\n",
    "  en_x=  Embedding(num_encoder_tokens, emb_sz)(encoder_inputs)\n",
    "  encoder = LSTM(lstm_sz, return_state=True)\n",
    "  encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "  # We discard `encoder_outputs` and only keep the states.\n",
    "  encoder_states = [state_h, state_c]\n",
    "  \n",
    "  # Encoder model\n",
    "  encoder_model = Model(encoder_inputs, encoder_states)\n",
    "  \n",
    "  \n",
    "  # Set up the decoder, using `encoder_states` as initial state.\n",
    "  decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "  dex=  Embedding(num_decoder_tokens, emb_sz)\n",
    "\n",
    "  final_dex= dex(decoder_inputs)\n",
    "\n",
    "\n",
    "  decoder_lstm = LSTM(lstm_sz, return_sequences=True, return_state=True)\n",
    "\n",
    "  decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                      initial_state=encoder_states)\n",
    "\n",
    "  decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "  decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "  \n",
    "  # Decoder model: Re-build based on explicit state inputs. Needed for step-by-step inference:\n",
    "  decoder_state_input_h = Input(shape=(lstm_sz,))\n",
    "  decoder_state_input_c = Input(shape=(lstm_sz,))\n",
    "  decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "  decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex, initial_state=decoder_states_inputs)\n",
    "  decoder_states2 = [state_h2, state_c2]\n",
    "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "  decoder_model = Model(\n",
    "  [decoder_inputs] + decoder_states_inputs,\n",
    "  [decoder_outputs2] + decoder_states2)  \n",
    "\n",
    "  return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 50)             101300    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 50)             220700    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 50),                 20200     ['embedding[0][0]']           \n",
      "                              (None, 50),                                                         \n",
      "                              (None, 50)]                                                         \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 50),           20200     ['embedding_1[0][0]',         \n",
      "                              (None, 50),                            'lstm[0][1]',                \n",
      "                              (None, 50)]                            'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 4414)           225114    ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 587514 (2.24 MB)\n",
      "Trainable params: 587514 (2.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = seq2seq(num_decoder_tokens, num_encoder_tokens, emb_size, emb_size)\n",
    "print(model.summary())\n",
    "# plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 13s 76ms/step - loss: 4.2137 - acc: 0.7491 - val_loss: 1.9767 - val_acc: 0.7253\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 1.5405 - acc: 0.7619 - val_loss: 1.5979 - val_acc: 0.7390\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 1.3247 - acc: 0.8112 - val_loss: 1.4660 - val_acc: 0.7878\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 8s 67ms/step - loss: 1.2408 - acc: 0.8274 - val_loss: 1.4101 - val_acc: 0.7989\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 1.1974 - acc: 0.8318 - val_loss: 1.3758 - val_acc: 0.8037\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 1.1686 - acc: 0.8330 - val_loss: 1.3558 - val_acc: 0.8045\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 1.1409 - acc: 0.8337 - val_loss: 1.3255 - val_acc: 0.8050\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 1.1136 - acc: 0.8360 - val_loss: 1.3029 - val_acc: 0.8093\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 1.0906 - acc: 0.8375 - val_loss: 1.2844 - val_acc: 0.8124\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 1.0710 - acc: 0.8385 - val_loss: 1.2714 - val_acc: 0.8126\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 8s 68ms/step - loss: 1.0542 - acc: 0.8404 - val_loss: 1.2578 - val_acc: 0.8175\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 1.0384 - acc: 0.8425 - val_loss: 1.2421 - val_acc: 0.8189\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 8s 67ms/step - loss: 1.0242 - acc: 0.8446 - val_loss: 1.2333 - val_acc: 0.8246\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 8s 68ms/step - loss: 1.0113 - acc: 0.8457 - val_loss: 1.2259 - val_acc: 0.8247\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.9999 - acc: 0.8463 - val_loss: 1.2187 - val_acc: 0.8275\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.9892 - acc: 0.8474 - val_loss: 1.2145 - val_acc: 0.8276\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.9789 - acc: 0.8483 - val_loss: 1.2027 - val_acc: 0.8289\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.9694 - acc: 0.8491 - val_loss: 1.2082 - val_acc: 0.8264\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.9602 - acc: 0.8499 - val_loss: 1.1962 - val_acc: 0.8297\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.9515 - acc: 0.8508 - val_loss: 1.1919 - val_acc: 0.8292\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.9433 - acc: 0.8517 - val_loss: 1.1871 - val_acc: 0.8307\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.9355 - acc: 0.8527 - val_loss: 1.1861 - val_acc: 0.8315\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 0.9284 - acc: 0.8533 - val_loss: 1.1785 - val_acc: 0.8327\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.9214 - acc: 0.8540 - val_loss: 1.1797 - val_acc: 0.8322\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.9151 - acc: 0.8543 - val_loss: 1.1738 - val_acc: 0.8338\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.9086 - acc: 0.8550 - val_loss: 1.1681 - val_acc: 0.8336\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.9027 - acc: 0.8555 - val_loss: 1.1707 - val_acc: 0.8337\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.8974 - acc: 0.8557 - val_loss: 1.1624 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.8918 - acc: 0.8562 - val_loss: 1.1591 - val_acc: 0.8349\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 8s 66ms/step - loss: 0.8858 - acc: 0.8569 - val_loss: 1.1602 - val_acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ebcf756a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size = 64,\n",
    "          epochs = 30,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create the same model but with the embedding layer has a mask_zero = true\n",
    "def seq2seq(num_decoder_tokens, num_encoder_tokens, emb_sz, lstm_sz):\n",
    "  \n",
    "  encoder_inputs = Input(shape=(None,))\n",
    "  \n",
    "  en_x=  Embedding(num_encoder_tokens, emb_sz, mask_zero = True)(encoder_inputs)\n",
    "  \n",
    "  encoder = LSTM(lstm_sz, return_state=True)\n",
    "  \n",
    "  encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "\n",
    "  \n",
    "  # We discard `encoder_outputs` and only keep the states.\n",
    "  \n",
    "  encoder_states = [state_h, state_c]\n",
    "  \n",
    "  # Encoder model\n",
    "  encoder_model = Model(encoder_inputs, encoder_states)\n",
    "  \n",
    "  \n",
    "  # Set up the decoder, using `encoder_states` as initial state.\n",
    "  decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "  dex=  Embedding(num_decoder_tokens, emb_sz, mask_zero = True)\n",
    "\n",
    "  final_dex= dex(decoder_inputs)\n",
    "\n",
    "\n",
    "  decoder_lstm = LSTM(lstm_sz, return_sequences=True, return_state=True)\n",
    "\n",
    "  decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                      initial_state=encoder_states)\n",
    "\n",
    "  decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "  decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "  \n",
    "  # Decoder model: Re-build based on explicit state inputs. Needed for step-by-step inference:\n",
    "  decoder_state_input_h = Input(shape=(lstm_sz,))\n",
    "  decoder_state_input_c = Input(shape=(lstm_sz,))\n",
    "  decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "  decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex, initial_state=decoder_states_inputs)\n",
    "  decoder_states2 = [state_h2, state_c2]\n",
    "  decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "  decoder_model = Model(\n",
    "  [decoder_inputs] + decoder_states_inputs,\n",
    "  [decoder_outputs2] + decoder_states2)  \n",
    "\n",
    "  return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, None, 50)             101300    ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, None, 50)             220700    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 50),                 20200     ['embedding_2[0][0]']         \n",
      "                              (None, 50),                                                         \n",
      "                              (None, 50)]                                                         \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 50),           20200     ['embedding_3[0][0]',         \n",
      "                              (None, 50),                            'lstm_2[0][1]',              \n",
      "                              (None, 50)]                            'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 4414)           225114    ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 587514 (2.24 MB)\n",
      "Trainable params: 587514 (2.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "125/125 [==============================] - 15s 85ms/step - loss: 6.5288 - acc: 0.2127 - val_loss: 4.9913 - val_acc: 0.1878\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 4.7145 - acc: 0.2507 - val_loss: 4.8284 - val_acc: 0.3707\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 4.3767 - acc: 0.4069 - val_loss: 4.3846 - val_acc: 0.3707\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 4.0100 - acc: 0.4303 - val_loss: 4.1286 - val_acc: 0.4038\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.8101 - acc: 0.4466 - val_loss: 3.9907 - val_acc: 0.4181\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.6840 - acc: 0.4557 - val_loss: 3.8957 - val_acc: 0.4204\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.5872 - acc: 0.4574 - val_loss: 3.8294 - val_acc: 0.4214\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 3.4996 - acc: 0.4626 - val_loss: 3.7558 - val_acc: 0.4352\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.4185 - acc: 0.4763 - val_loss: 3.6900 - val_acc: 0.4647\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.3443 - acc: 0.4871 - val_loss: 3.6353 - val_acc: 0.4651\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 3.2775 - acc: 0.4959 - val_loss: 3.5852 - val_acc: 0.4770\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 3.2173 - acc: 0.5057 - val_loss: 3.5306 - val_acc: 0.4820\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.1600 - acc: 0.5111 - val_loss: 3.4898 - val_acc: 0.4893\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.1077 - acc: 0.5194 - val_loss: 3.4584 - val_acc: 0.4957\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 3.0587 - acc: 0.5293 - val_loss: 3.4215 - val_acc: 0.5069\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 3.0113 - acc: 0.5371 - val_loss: 3.3825 - val_acc: 0.5177\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 2.9671 - acc: 0.5431 - val_loss: 3.3606 - val_acc: 0.5211\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 2.9255 - acc: 0.5474 - val_loss: 3.3270 - val_acc: 0.5242\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 2.8875 - acc: 0.5512 - val_loss: 3.3063 - val_acc: 0.5269\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 2.8505 - acc: 0.5549 - val_loss: 3.2846 - val_acc: 0.5325\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 2.8173 - acc: 0.5583 - val_loss: 3.2628 - val_acc: 0.5329\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 2.7854 - acc: 0.5609 - val_loss: 3.2464 - val_acc: 0.5380\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 9s 68ms/step - loss: 2.7555 - acc: 0.5648 - val_loss: 3.2279 - val_acc: 0.5408\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 8s 68ms/step - loss: 2.7264 - acc: 0.5662 - val_loss: 3.2142 - val_acc: 0.5410\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 2.6990 - acc: 0.5698 - val_loss: 3.2035 - val_acc: 0.5433\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 8s 68ms/step - loss: 2.6720 - acc: 0.5726 - val_loss: 3.1843 - val_acc: 0.5453\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 2.6461 - acc: 0.5763 - val_loss: 3.1783 - val_acc: 0.5483\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 2.6202 - acc: 0.5797 - val_loss: 3.1615 - val_acc: 0.5476\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 11s 85ms/step - loss: 2.5950 - acc: 0.5842 - val_loss: 3.1588 - val_acc: 0.5498\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 9s 76ms/step - loss: 2.5710 - acc: 0.5872 - val_loss: 3.1453 - val_acc: 0.5507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ebd0041290>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = seq2seq(num_decoder_tokens, num_encoder_tokens, emb_size, emb_size)\n",
    "print(model.summary())\n",
    "# plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size = 64,\n",
    "          epochs = 30,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can notice that the accuracy with mask zero went down as we have said \n",
    "\n",
    "- Now let's test our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, None, 50)             220700    ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 50),           20200     ['embedding_3[0][0]',         \n",
      "                              (None, 50),                            'input_7[0][0]',             \n",
      "                              (None, 50)]                            'input_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 4414)           225114    ['lstm_3[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 466014 (1.78 MB)\n",
      "Trainable params: 466014 (1.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# using the model for predicting \n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_to_french)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, sep=' '):\n",
    "      # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = french_to_idx[start_tok]\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_tok = idx_to_french[sampled_token_index]\n",
    "        decoded_sentence += sep + sampled_tok\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_tok == end_tok or\n",
    "           len(decoded_sentence) > 20):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "-\n",
      "Input sentence: 0    go\n",
      "Name: input, dtype: object\n",
      "Decoded sentence:  à la maison _END\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "-\n",
      "Input sentence: 1    go\n",
      "Name: input, dtype: object\n",
      "Decoded sentence:  à la maison _END\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "-\n",
      "Input sentence: 2    go\n",
      "Name: input, dtype: object\n",
      "Decoded sentence:  à la maison _END\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "-\n",
      "Input sentence: 3    go\n",
      "Name: input, dtype: object\n",
      "Decoded sentence:  à la maison _END\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "-\n",
      "Input sentence: 4    hi\n",
      "Name: input, dtype: object\n",
      "Decoded sentence:  du calme _END\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(5): #[14077,20122,40035,40064, 40056, 40068, 40090, 40095, 40100, 40119, 40131, 40136, 40150, 40153]:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', lines.input[seq_index: seq_index + 1])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
